{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28f0020d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "#  Set the working directory to the folder containing the top-level ultralytics package\n",
    "os.chdir(\"/workspace\")  # change to your workspace root where ultralytics folder exists\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88db1672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspace/ultralytics\n"
     ]
    }
   ],
   "source": [
    "#  Add the top-level ultralytics folder to Python path\n",
    "os.chdir(\"/workspace/ultralytics\")\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e251cdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 250 epochs...\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.200 ğŸš€ Python-3.10.12 torch-2.4.0a0+f70bd71a48.nv24.06 CUDA:0 (NVIDIA A100-SXM4-80GB, 81051MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=disk, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/workspace/datasets/KITTI/kitti.yml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=250, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n_base_patience202, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/workspace/ultralytics/runs/detect/yolov8n_base_patience202, save_frames=False, save_json=False, save_period=40, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752677  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,012,213 parameters, 3,012,197 gradients\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.1 ms, read: 2135.9Â±243.5 MB/s, size: 728.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/datasets/KITTI/labels/train.cache... 5984 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5984/5984 5.5Mit/s 0.0s0s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (7.8GB Disk): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5984/5984 32.3Kit/s 0.2ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.2Â±0.1 ms, read: 1679.6Â±862.8 MB/s, size: 814.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/datasets/KITTI/labels/val.cache... 1497 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1497/1497 1.7Mit/s 0.0ss\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (1.9GB Disk): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1497/1497 34.0Kit/s 0.0s\n",
      "Plotting labels to /workspace/ultralytics/runs/detect/yolov8n_base_patience202/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m/workspace/ultralytics/runs/detect/yolov8n_base_patience202\u001b[0m\n",
      "Starting training for 250 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/250      15.9G      1.261      2.379      1.162        365       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:430.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 4.3it/s 5.6s0.2s\n",
      "                   all       1497       7772      0.609      0.438       0.44      0.276\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/250      15.9G      1.136      1.444      1.096        267       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.9it/s 1:400.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.1it/s 4.7s0.2s\n",
      "                   all       1497       7772      0.708      0.519      0.569       0.36\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/250      15.9G      1.134      1.244      1.102        335       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:420.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.7it/s 4.2s0.2s\n",
      "                   all       1497       7772      0.588      0.479      0.521      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/250      15.9G      1.132      1.066      1.109        372       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:420.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.7it/s 4.2s0.2s\n",
      "                   all       1497       7772       0.53      0.582      0.561      0.343\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/250      15.9G      1.086     0.9215      1.097        366       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.9it/s 1:410.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.8it/s 4.1s0.2s\n",
      "                   all       1497       7772       0.66      0.548      0.643      0.399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/250      15.9G      1.055     0.8558      1.083        342       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:410.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.8it/s 4.1s0.2s\n",
      "                   all       1497       7772      0.675      0.627      0.683      0.447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/250      15.9G      1.034      0.809      1.076        369       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:420.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.8it/s 4.1s0.2s\n",
      "                   all       1497       7772      0.698      0.627      0.683      0.435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/250      15.9G      1.014     0.7773      1.064        356       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:420.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.9it/s 4.1s0.2s\n",
      "                   all       1497       7772      0.717      0.652      0.698      0.453\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/250      15.9G     0.9878     0.7454      1.052        448       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:420.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.7it/s 4.2s0.2s\n",
      "                   all       1497       7772      0.763      0.691      0.759      0.501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/250      15.9G     0.9758     0.7288      1.046        335       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:430.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.9it/s 4.1s0.2s\n",
      "                   all       1497       7772       0.68      0.699      0.743      0.491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/250      15.9G      0.955     0.6974      1.037        358       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:420.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.9it/s 4.1s0.2s\n",
      "                   all       1497       7772      0.712      0.755      0.774      0.527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/250      15.9G     0.9465     0.6924      1.034        317       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:430.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.9it/s 4.1s0.2s\n",
      "                   all       1497       7772      0.767      0.713      0.783      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/250      15.9G      0.937     0.6762      1.031        333       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:430.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.6it/s 4.3s0.2s\n",
      "                   all       1497       7772      0.774      0.738      0.791       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/250      15.9G      0.918     0.6603      1.021        288       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:420.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.9it/s 4.1s0.2s\n",
      "                   all       1497       7772      0.793      0.743      0.797      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/250      15.9G     0.9119     0.6527      1.019        424       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:420.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.9it/s 4.0s0.2s\n",
      "                   all       1497       7772      0.779      0.772      0.815      0.554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/250      15.9G     0.9039     0.6423      1.016        307       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.9it/s 1:410.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.9it/s 4.1s0.2s\n",
      "                   all       1497       7772      0.814      0.771      0.816      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/250      15.9G     0.8936     0.6321      1.008        330       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:420.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.9it/s 4.0s0.2s\n",
      "                   all       1497       7772       0.82      0.736      0.819      0.567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/250      15.9G     0.8859     0.6219      1.007        344       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:430.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.9it/s 4.1s0.2s\n",
      "                   all       1497       7772      0.809      0.752       0.82      0.577\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/250      15.9G     0.8735     0.6122      1.002        306       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:420.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.9it/s 4.1s0.2s\n",
      "                   all       1497       7772      0.812      0.758      0.824      0.581\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/250      15.9G     0.8733     0.6075     0.9987        437       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:410.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.6it/s 4.3s0.2s\n",
      "                   all       1497       7772      0.791       0.79      0.836      0.593\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/250      15.9G     0.8656     0.6028      0.996        366       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:420.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.9it/s 4.0s0.2s\n",
      "                   all       1497       7772      0.813       0.76      0.819       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/250      15.9G      0.858     0.5917     0.9927        385       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.9it/s 1:400.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.9it/s 4.1s0.2s\n",
      "                   all       1497       7772      0.832      0.769      0.839      0.601\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/250      15.9G     0.8528     0.5897     0.9922        297       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.8it/s 1:420.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.9it/s 4.0s0.2s\n",
      "                   all       1497       7772      0.857      0.736      0.835       0.61\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/250      15.9G      0.843     0.5769     0.9856        439       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.9it/s 1:410.4sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.9it/s 4.0s0.2s\n",
      "                   all       1497       7772      0.876      0.766      0.854      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/250      15.9G     0.8357     0.5743     0.9837        365       1280: 100% â”â”â”â”â”â”â”â”â”â”â”â” 187/187 1.9it/s 1:400.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 5.9it/s 4.1s0.2s\n",
      "                   all       1497       7772      0.844      0.796      0.847      0.606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/250      15.9G     0.8362     0.5736     0.9894        279       1280: 30% â”â”â”â•¸â”€â”€â”€â”€â”€â”€â”€â”€ 57/187 2.4it/s 28.8s<53.5s"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import time\n",
    "import torch\n",
    "\n",
    "# === Parameters ===\n",
    "dataset_yaml = \"/workspace/datasets/KITTI/kitti.yml\"\n",
    "run_name = \"yolov8n_base_patience20\"\n",
    "epochs = 250                # max epochs; early stopping may stop earlier\n",
    "imgsz = 1280              # research-level resolution\n",
    "batch_size = 32           # adjust according to VRAM\n",
    "workers = 2               # safer for shared memory\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "cache_images = \"disk\"\n",
    "amp = True                # mixed precision\n",
    "save_interval = 40         # save checkpoint every 2 epochs\n",
    "patience = 20             # early stopping patience\n",
    "\n",
    "# === Initialize YOLOv8n ===\n",
    "model = YOLO(\"yolov8n.pt\")  # pre-trained weights\n",
    "\n",
    "\n",
    "# === Start training ===\n",
    "start_time = time.time()\n",
    "print(f\"Starting training for {epochs} epochs...\\n\")\n",
    "\n",
    "results = model.train(\n",
    "    data=dataset_yaml,\n",
    "    epochs=epochs,\n",
    "    imgsz=imgsz,\n",
    "    batch=batch_size,\n",
    "    workers=workers,\n",
    "    device=device,\n",
    "    cache=cache_images,\n",
    "    name=run_name,\n",
    "    save=True,\n",
    "    amp=amp,\n",
    "    patience=patience,\n",
    "    save_period=save_interval\n",
    ")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTraining completed in {total_time/3600:.2f} hours\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9abfb6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (file): 5.99 MB\n",
      "Model parameters: 11.49 MB\n",
      "\n",
      "0: 1280x1280 (no detections), 5.3ms\n",
      "Speed: 0.0ms preprocess, 5.3ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.2ms\n",
      "Speed: 0.0ms preprocess, 5.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 1.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.9ms\n",
      "Speed: 0.0ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.2ms\n",
      "Speed: 0.0ms preprocess, 5.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 4.9ms\n",
      "Speed: 0.0ms preprocess, 4.9ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "Inference FPS (1280x1280): 127.75\n",
      "\n",
      "Running YOLOv8 validation...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.2Â±0.1 ms, read: 2216.3Â±359.9 MB/s, size: 809.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/datasets/KITTI/labels/val.cache... 1497 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1497/1497 2.4Mit/s 0.0s0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 24/24 2.9it/s 8.4s0.2s\n",
      "                   all       1497       7772       0.93      0.901      0.939      0.767\n",
      "                   Car       1333       5680      0.964       0.96      0.987      0.885\n",
      "                   Van        425        563      0.959       0.96      0.981       0.87\n",
      "                 Truck        190        198      0.966      0.929      0.969       0.89\n",
      "            Pedestrian        357        896      0.951      0.788      0.905      0.572\n",
      "        Person_sitting         13         30      0.806      0.833      0.841      0.582\n",
      "               Cyclist        222        306      0.922      0.888      0.945      0.739\n",
      "                  Tram         76         99       0.94      0.944      0.946      0.829\n",
      "Speed: 0.7ms preprocess, 0.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Saving /workspace/yolov8n_base_sdgpat_20val/eval_metrics/predictions.json...\n",
      "Results saved to \u001b[1m/workspace/yolov8n_base_sdgpat_20val/eval_metrics\u001b[0m\n",
      "Validation time: 12.72 seconds\n",
      "Validation results saved to /workspace/yolov8n_base_sdgpat_20val\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import time\n",
    "from ultralytics import YOLO  # Use YOLOv8's interface\n",
    "\n",
    "weights = \"runs/detect/yolov8n_base_patience20/weights/best.pt\"\n",
    "dataset_yaml = \"/workspace/datasets/KITTI/kitti.yml\"\n",
    "results_dir = \"/workspace/yolov8n_base_sdgpat_20val\"\n",
    "\n",
    "# ------------------- Device -------------------\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ------------------- Load model -------------------\n",
    "model = YOLO(weights)  # Load the model using YOLOv8\n",
    "params = sum(p.numel() for p in model.model.parameters())\n",
    "params_mb = params * 4 / (1024**2)  # float32 -> 4 bytes\n",
    "model_size_mb = Path(weights).stat().st_size / 1024**2  # file size in MB\n",
    "\n",
    "print(f\"Model size (file): {model_size_mb:.2f} MB\")\n",
    "print(f\"Model parameters: {params_mb:.2f} MB\")\n",
    "\n",
    "# ------------------- FPS Measurement -------------------\n",
    "dummy_input = torch.randn(1, 3, 1280, 1280).to(device) / 255.0  # Normalize the dummy input\n",
    "# Warm-up\n",
    "for _ in range(5):\n",
    "    _ = model(dummy_input)  # Use the model directly for inference\n",
    "\n",
    "n_runs = 50\n",
    "start_time = time.time()\n",
    "for _ in range(n_runs):\n",
    "    _ = model(dummy_input)  # Use the model directly for inference\n",
    "end_time = time.time()\n",
    "\n",
    "fps = n_runs / (end_time - start_time)\n",
    "print(f\"Inference FPS (1280x1280): {fps:.2f}\")\n",
    "\n",
    "# ------------------- Run Validation -------------------\n",
    "print(\"\\nRunning YOLOv8 validation...\")\n",
    "start_val_time = time.time()\n",
    "model.val(\n",
    "    data=dataset_yaml,  # Validation dataset\n",
    "    imgsz=1280,          # Image size\n",
    "    batch=64,            # Corrected batch size argument\n",
    "    device=device,       # Device\n",
    "    project=results_dir, # Results directory\n",
    "    name=\"eval_metrics\", # Name for saved results\n",
    "    save_json=True,      # Save results as JSON\n",
    "    exist_ok=True,       # Overwrite if results directory exists\n",
    "    verbose=True         # Show verbose output\n",
    ")\n",
    "end_val_time = time.time()\n",
    "\n",
    "val_time = end_val_time - start_val_time\n",
    "print(f\"Validation time: {val_time:.2f} seconds\")\n",
    "print(f\"Validation results saved to {results_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0931ecaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/ultralytics/runs/detect/yolov8n_base_patience20.zip'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Specify the folder path and the destination zip file path\n",
    "folder_path = 'runs/detect/yolov8n_base_patience20'\n",
    "zip_file_path = 'runs/detect/yolov8n_base_patience20.zip'\n",
    "\n",
    "# Create a zip file from the folder\n",
    "shutil.make_archive(zip_file_path.replace('.zip', ''), 'zip', folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15005c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/vals/yolov8n_base_sdgpat_20val.zip'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Specify the folder path and the destination zip file path\n",
    "folder_path = '/workspace/vals/yolov8n_base_sdgpat_20val'\n",
    "zip_file_path = '/workspace/vals/yolov8n_base_sdgpat_20val.zip'\n",
    "\n",
    "# Create a zip file from the folder\n",
    "shutil.make_archive(zip_file_path.replace('.zip', ''), 'zip', folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa0484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
