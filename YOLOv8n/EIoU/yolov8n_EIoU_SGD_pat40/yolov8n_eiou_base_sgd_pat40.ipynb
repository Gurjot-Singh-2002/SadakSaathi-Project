{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44dac5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "#  Set the working directory to the folder containing the top-level ultralytics package\n",
    "os.chdir(\"/workspace\")  # change to your workspace root where ultralytics folder exists\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb5a92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ultralytics'...\n",
      "remote: Enumerating objects: 67800, done.\u001b[K\n",
      "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
      "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
      "remote: Total 67800 (delta 61), reused 30 (delta 21), pack-reused 67677 (from 2)\u001b[K\n",
      "Receiving objects: 100% (67800/67800), 36.01 MiB | 8.35 MiB/s, done.\n",
      "Resolving deltas: 100% (50671/50671), done.\n",
      "Updating files: 100% (778/778), done.\n",
      "/workspace/ultralytics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/ultralytics.git\n",
    "%cd ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39a77fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspace/ultralytics\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "#  Set the working directory to the folder containing the top-level ultralytics package\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7993037f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspace/ultralytics\n"
     ]
    }
   ],
   "source": [
    "#  Add the top-level ultralytics folder to Python path\n",
    "os.chdir(\"/workspace/ultralytics\")\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd1b28bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ no model scale passed. Assuming scale='n'.\n",
      "Original model loaded \n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# -------------------------------\n",
    "# Load YAML (with original SPPF)\n",
    "# -------------------------------\n",
    "model = YOLO('yolov8.yaml')\n",
    "print(\"Original model loaded \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a423acd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/ultralytics/ultralytics/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "print(ultralytics.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10a64421",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ no model scale passed. Assuming scale='n'.\n",
      "DetectionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (2): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (4): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (6): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (8): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): SPPF(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (10): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (11): Concat()\n",
      "    (12): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (14): Concat()\n",
      "    (15): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): Conv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (17): Concat()\n",
      "    (18): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (20): Concat()\n",
      "    (21): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (22): Detect(\n",
      "      (cv2): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (cv3): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 7, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 7, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 7, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (dfl): DFL(\n",
      "        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from ultralytics.models.yolo.model import YOLO\n",
    "\n",
    "# Load your YOLOv8 model (with CBAM if added)\n",
    "model = YOLO(\"ultralytics/cfg/models/v8/yolov8.yaml\")\n",
    "\n",
    "# Print the full architecture\n",
    "print(model.model)   # model.model contains the actual PyTorch nn.Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1aa3a63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspace/ultralytics\n"
     ]
    }
   ],
   "source": [
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b926c60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ no model scale passed. Assuming scale='n'.\n",
      "[Sanity Check] loss_iou = 0.3275921940803528, loss_dfl = 2.7725887298583984\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- Load model ---\n",
    "model = YOLO(\"yolov8.yaml\")  # your custom model\n",
    "model.eval()  # evaluation mode\n",
    "\n",
    "# --- Create dummy input ---\n",
    "dummy_img = torch.randn(1, 3, 640, 640)  # batch_size=1, 3 channels, 640x640\n",
    "\n",
    "# --- Forward pass through the model ---\n",
    "with torch.no_grad():\n",
    "    preds = model.model(dummy_img)  # list of outputs from YOLO layers\n",
    "\n",
    "# --- Pick one output and compute a dummy EIoU loss ---\n",
    "from ultralytics.utils.loss import BboxLoss\n",
    "from ultralytics.utils.metrics import bbox_iou\n",
    "\n",
    "# fake target boxes (x1,y1,x2,y2)\n",
    "target_boxes = torch.tensor([[100, 100, 200, 200]], dtype=torch.float32)\n",
    "pred_boxes = torch.tensor([[110, 110, 210, 210]], dtype=torch.float32)\n",
    "\n",
    "bbox_loss_fn = BboxLoss()\n",
    "# Mask & dummy target scores\n",
    "fg_mask = torch.tensor([True])\n",
    "target_scores = torch.tensor([[1.0]])\n",
    "target_scores_sum = torch.tensor(1.0)\n",
    "\n",
    "loss_iou, loss_dfl = bbox_loss_fn(\n",
    "    pred_dist=torch.zeros(1, 16, 4),      # dummy DFL input\n",
    "    pred_bboxes=pred_boxes,\n",
    "    anchor_points=torch.zeros(1, 2),      # dummy anchors\n",
    "    target_bboxes=target_boxes,\n",
    "    target_scores=target_scores,\n",
    "    target_scores_sum=target_scores_sum,\n",
    "    fg_mask=fg_mask\n",
    ")\n",
    "\n",
    "print(f\"[Sanity Check] loss_iou = {loss_iou.item()}, loss_dfl = {loss_dfl.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import time\n",
    "import torch\n",
    "\n",
    "# === Device setup ===\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# === Load default YOLOv8 architecture ===\n",
    "model = YOLO(\"yolov8n.yaml\").to(device)  # Use default YAML, not custom CBAM YAML\n",
    "\n",
    "# === Set box loss to EIoU only ===\n",
    "model.box_loss_type = \"eiou\"  # Enable EIoU\n",
    "# Classification and objectness remain default BCE\n",
    "model.cls_loss_type = \"bce\"  # placeholder (doesn't impact)\n",
    "model.obj_loss_type = \"bce\"  # placeholder (doesn't impact)\n",
    "\n",
    "# === Enable EMA ===\n",
    "model.ema = True\n",
    "\n",
    "# === Training parameters ===\n",
    "dataset_yaml = \"/workspace/datasets/KITTI/kitti.yml\"  # Custom KITTI dataset YAML\n",
    "run_name = \"yolov8n_eiou_base_sgd_pat40\"  # Run name for saving logs and weights\n",
    "epochs = 250            # Max epochs\n",
    "imgsz = 1280            # Image size\n",
    "batch_size = 32         # Batch size\n",
    "workers = 2             # Data loader workers\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "cache_images = \"disk\"   # Cache images to disk\n",
    "amp = True              # Mixed precision\n",
    "save_interval = 50      # Save checkpoint every 50 epochs\n",
    "patience = 40           # Early stopping patience\n",
    "\n",
    "# === EMA status ===\n",
    "print(\"\\n=== EMA STATUS ===\")\n",
    "print(f\"EMA enabled: {model.ema}\")\n",
    "\n",
    "# === Detect layer info ===\n",
    "print(\"\\n=== DETECT LAYER INFO ===\")\n",
    "detect_layer = model.model.model[-1]\n",
    "print(f\"  Classes (nc): {detect_layer.nc}\")\n",
    "try:\n",
    "    print(f\"  Strides: {detect_layer.stride}\")\n",
    "    print(f\"  Number of detection heads: {len(detect_layer.stride)}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Could not read strides/heads: {e}\")\n",
    "\n",
    "# === Model summary ===\n",
    "print(\"\\n=== MODEL SUMMARY ===\")\n",
    "print(model.model)\n",
    "\n",
    "# === Loss type verification ===\n",
    "print(\"\\n=== LOSS TYPE VERIFICATION ===\")\n",
    "print(f\"Box loss type: {model.box_loss_type}\")\n",
    "print(f\"Class loss type: {model.cls_loss_type}\")\n",
    "print(f\"Object loss type: {model.obj_loss_type}\")\n",
    "\n",
    "# === Start full training ===\n",
    "print(\"\\n=== STARTING FULL TRAINING ===\")\n",
    "start_time = time.time()\n",
    "\n",
    "results = model.train(\n",
    "    data=dataset_yaml,\n",
    "    pretrained=\"yolov8n.pt\",  # Use COCO pretrained weights\n",
    "    epochs=epochs,\n",
    "    imgsz=imgsz,\n",
    "    batch=batch_size,\n",
    "    workers=workers,\n",
    "    device=device,\n",
    "    cache=cache_images,\n",
    "    name=run_name,\n",
    "    save=True,\n",
    "    amp=amp,\n",
    "    patience=patience,\n",
    "    save_period=save_interval\n",
    ")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTraining completed in {total_time/3600:.2f} hours\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29355077",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EMA STATUS ===\n",
      "EMA enabled: True\n",
      "\n",
      "=== DETECT LAYER INFO ===\n",
      "  Classes (nc): 7\n",
      "  Strides: tensor([ 8., 16., 32.], device='cuda:0')\n",
      "  Number of detection heads: 3\n",
      "\n",
      "=== MODEL SUMMARY ===\n",
      "DetectionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (2): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (4): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (6): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (8): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): SPPF(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (10): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (11): Concat()\n",
      "    (12): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (14): Concat()\n",
      "    (15): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): Conv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (17): Concat()\n",
      "    (18): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (20): Concat()\n",
      "    (21): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (22): Detect(\n",
      "      (cv2): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (cv3): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 7, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 7, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 7, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (dfl): DFL(\n",
      "        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "=== LOSS TYPE VERIFICATION ===\n",
      "Box loss type: eiou\n",
      "Class loss type: bce\n",
      "Object loss type: bce\n",
      "\n",
      "=== STARTING FULL TRAINING ===\n",
      "New https://pypi.org/project/ultralytics/8.3.202 available 😃 Update with 'pip install -U ultralytics'\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Ultralytics 8.3.200 🚀 Python-3.10.12 torch-2.4.0a0+f70bd71a48.nv24.06 CUDA:0 (NVIDIA A100-SXM4-80GB, 81051MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=disk, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/workspace/datasets/KITTI/kitti.yml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=250, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=just_a_check_for_params, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=40, perspective=0.0, plots=True, pose=12.0, pretrained=yolov8n.pt, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/workspace/ultralytics/runs/detect/just_a_check_for_params, save_frames=False, save_json=False, save_period=50, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752677  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n",
      "YOLOv8n summary: 129 layers, 3,012,213 parameters, 3,012,197 gradients\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.1 ms, read: 1994.2±100.7 MB/s, size: 728.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/datasets/KITTI/labels/train.cache... 5984 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 5984/5984 7.3Mit/s 0.0s0s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (7.8GB Disk): 100% ━━━━━━━━━━━━ 5984/5984 31.8Kit/s 0.2ss\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.2±0.1 ms, read: 1432.4±389.1 MB/s, size: 814.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/datasets/KITTI/labels/val.cache... 1497 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1497/1497 1.3Mit/s 0.0ss\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (1.9GB Disk): 100% ━━━━━━━━━━━━ 1497/1497 32.6Kit/s 0.0s\n",
      "Plotting labels to /workspace/ultralytics/runs/detect/just_a_check_for_params/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m/workspace/ultralytics/runs/detect/just_a_check_for_params\u001b[0m\n",
      "Starting training for 250 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/250      16.4G      1.545      4.316      1.328        301       1280: 9% ━─────────── 17/187 4.3it/s 9.1s<39.3s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== STARTING FULL TRAINING ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 61\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_yaml\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myolov8n.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use COCO pretrained weights\u001b[39;49;00m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimgsz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_interval\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m total_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_time\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3600\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m hours\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspace/ultralytics/ultralytics/engine/model.py:800\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m--> 800\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m/workspace/ultralytics/ultralytics/engine/trainer.py:235\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/ultralytics/ultralytics/engine/trainer.py:420\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;66;03m# decouple inference and loss calculations for torch.compile convenience\u001b[39;00m\n\u001b[1;32m    419\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 420\u001b[0m loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;241m=\u001b[39m \u001b[43munwrap_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/workspace/ultralytics/ultralytics/nn/tasks.py:339\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/ultralytics/ultralytics/utils/loss.py:263\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m(self, preds, batch)\u001b[0m\n\u001b[1;32m    260\u001b[0m imgsz = torch.tensor(feats[0].shape[2:], device=self.device, dtype=dtype) * self.stride[0]  # image size (h,w)\n\u001b[1;32m    261\u001b[0m anchor_points, stride_tensor = make_anchors(feats, self.stride, 0.5)\n\u001b[0;32m--> 263\u001b[0m # Targets\n\u001b[1;32m    264\u001b[0m targets = torch.cat((batch[\"batch_idx\"].view(-1, 1), batch[\"cls\"].view(-1, 1), batch[\"bboxes\"]), 1)\n\u001b[1;32m    265\u001b[0m targets = self.preprocess(targets, batch_size, scale_tensor=imgsz[[1, 0, 1, 0]])\n",
      "File \u001b[0;32m/workspace/ultralytics/ultralytics/utils/loss.py:226\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(self, targets, batch_size, scale_tensor)\u001b[0m\n\u001b[1;32m    224\u001b[0m if nl == 0:\n\u001b[1;32m    225\u001b[0m     out = torch.zeros(batch_size, 0, ne - 1, device=self.device)\n\u001b[0;32m--> 226\u001b[0m else:\n\u001b[1;32m    227\u001b[0m     i = targets[:, 0]  # image index\n\u001b[1;32m    228\u001b[0m     _, counts = i.unique(return_counts=True)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:936\u001b[0m, in \u001b[0;36mTensor.unique\u001b[0;34m(self, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    928\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39munique,\n\u001b[1;32m    929\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m         dim\u001b[38;5;241m=\u001b[39mdim,\n\u001b[1;32m    935\u001b[0m     )\n\u001b[0;32m--> 936\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_jit_internal.py:502\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_jit_internal.py:500\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m     dispatch_flag \u001b[38;5;241m=\u001b[39m args[arg_index]\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dispatch_flag:\n\u001b[0;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_true\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_false(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py:986\u001b[0m, in \u001b[0;36m_return_counts\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_impl(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28msorted\u001b[39m, return_inverse, return_counts, dim)\n\u001b[0;32m--> 986\u001b[0m output, _, counts \u001b[38;5;241m=\u001b[39m \u001b[43m_unique_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, counts\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py:910\u001b[0m, in \u001b[0;36m_unique_impl\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    902\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39munique_dim(\n\u001b[1;32m    903\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    904\u001b[0m         dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    907\u001b[0m         return_counts\u001b[38;5;241m=\u001b[39mreturn_counts,\n\u001b[1;32m    908\u001b[0m     )\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 910\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unique2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, inverse_indices, counts\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import time\n",
    "import torch\n",
    "\n",
    "# === Device setup ===\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# === Load default YOLOv8 architecture ===\n",
    "model = YOLO(\"yolov8n.yaml\").to(device)  # Use default YAML, not custom CBAM YAML\n",
    "\n",
    "# === Set box loss to EIoU only ===\n",
    "model.box_loss_type = \"eiou\"  # Enable EIoU\n",
    "# Classification and objectness remain default BCE\n",
    "model.cls_loss_type = \"bce\"  # placeholder (doesn't impact)\n",
    "model.obj_loss_type = \"bce\"  # placeholder (doesn't impact)\n",
    "\n",
    "# === Enable EMA ===\n",
    "model.ema = True\n",
    "\n",
    "# === Training parameters ===\n",
    "dataset_yaml = \"/workspace/datasets/KITTI/kitti.yml\"  # Custom KITTI dataset YAML\n",
    "run_name = \"just_a_check_for_params\"  # Run name for saving logs and weights\n",
    "epochs = 250            # Max epochs\n",
    "imgsz = 1280            # Image size\n",
    "batch_size = 32         # Batch size\n",
    "workers = 2             # Data loader workers\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "cache_images = \"disk\"   # Cache images to disk\n",
    "amp = True              # Mixed precision\n",
    "save_interval = 50      # Save checkpoint every 50 epochs\n",
    "patience = 40           # Early stopping patience\n",
    "\n",
    "# === EMA status ===\n",
    "print(\"\\n=== EMA STATUS ===\")\n",
    "print(f\"EMA enabled: {model.ema}\")\n",
    "\n",
    "# === Detect layer info ===\n",
    "print(\"\\n=== DETECT LAYER INFO ===\")\n",
    "detect_layer = model.model.model[-1]\n",
    "print(f\"  Classes (nc): {detect_layer.nc}\")\n",
    "try:\n",
    "    print(f\"  Strides: {detect_layer.stride}\")\n",
    "    print(f\"  Number of detection heads: {len(detect_layer.stride)}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Could not read strides/heads: {e}\")\n",
    "\n",
    "# === Model summary ===\n",
    "print(\"\\n=== MODEL SUMMARY ===\")\n",
    "print(model.model)\n",
    "\n",
    "# === Loss type verification ===\n",
    "print(\"\\n=== LOSS TYPE VERIFICATION ===\")\n",
    "print(f\"Box loss type: {model.box_loss_type}\")\n",
    "print(f\"Class loss type: {model.cls_loss_type}\")\n",
    "print(f\"Object loss type: {model.obj_loss_type}\")\n",
    "\n",
    "# === Start full training ===\n",
    "print(\"\\n=== STARTING FULL TRAINING ===\")\n",
    "start_time = time.time()\n",
    "\n",
    "results = model.train(\n",
    "    data=dataset_yaml,\n",
    "    pretrained=\"yolov8n.pt\",  # Use COCO pretrained weights\n",
    "    epochs=epochs,\n",
    "    imgsz=imgsz,\n",
    "    batch=batch_size,\n",
    "    workers=workers,\n",
    "    device=device,\n",
    "    cache=cache_images,\n",
    "    name=run_name,\n",
    "    save=True,\n",
    "    amp=amp,\n",
    "    patience=patience,\n",
    "    save_period=save_interval\n",
    ")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTraining completed in {total_time/3600:.2f} hours\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e958a227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (file): 5.99 MB\n",
      "Model parameters: 11.49 MB\n",
      "\n",
      "0: 1280x1280 (no detections), 5.3ms\n",
      "Speed: 0.0ms preprocess, 5.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 2.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 1.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.2ms\n",
      "Speed: 0.0ms preprocess, 5.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.4ms\n",
      "Speed: 0.0ms preprocess, 5.4ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 1.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.5ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.4ms\n",
      "Speed: 0.0ms preprocess, 5.4ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 1.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 4.9ms\n",
      "Speed: 0.0ms preprocess, 4.9ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 4.9ms\n",
      "Speed: 0.0ms preprocess, 4.9ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 1.2ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "\n",
      "0: 1280x1280 (no detections), 5.2ms\n",
      "Speed: 0.0ms preprocess, 5.2ms inference, 1.4ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "Inference FPS (1280x1280): 126.64\n",
      "\n",
      "Running YOLOv8 validation...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2322.1±139.8 MB/s, size: 834.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/datasets/KITTI/labels/val.cache... 1497 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1497/1497 3.5Mit/s 0.0s0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 24/24 2.8it/s 8.7s0.2s\n",
      "                   all       1497       7772      0.892      0.909      0.933      0.759\n",
      "                   Car       1333       5680      0.946      0.965      0.986      0.874\n",
      "                   Van        425        563      0.923      0.961      0.979      0.858\n",
      "                 Truck        190        198      0.952      0.944      0.977      0.876\n",
      "            Pedestrian        357        896      0.902      0.835      0.904      0.574\n",
      "        Person_sitting         13         30      0.721      0.774      0.771      0.558\n",
      "               Cyclist        222        306      0.906      0.913      0.948      0.732\n",
      "                  Tram         76         99      0.896       0.97      0.966      0.842\n",
      "Speed: 0.7ms preprocess, 0.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Saving /workspace/yolov8n_eiou_base_sgd_pat40_val/eval_metrics/predictions.json...\n",
      "Results saved to \u001b[1m/workspace/yolov8n_eiou_base_sgd_pat40_val/eval_metrics\u001b[0m\n",
      "Validation time: 13.09 seconds\n",
      "Validation results saved to /workspace/yolov8n_eiou_base_sgd_pat40_val\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import time\n",
    "from ultralytics import YOLO  # Use YOLOv8's interface\n",
    "\n",
    "weights = \"runs/detect/yolov8n_eiou_base_sgd_pat40/weights/best.pt\"\n",
    "dataset_yaml = \"/workspace/datasets/KITTI/kitti.yml\"\n",
    "results_dir = \"/workspace/yolov8n_eiou_base_sgd_pat40_val\"\n",
    "\n",
    "# ------------------- Device -------------------\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ------------------- Load model -------------------\n",
    "model = YOLO(weights)  # Load the model using YOLOv8\n",
    "params = sum(p.numel() for p in model.model.parameters())\n",
    "params_mb = params * 4 / (1024**2)  # float32 -> 4 bytes\n",
    "model_size_mb = Path(weights).stat().st_size / 1024**2  # file size in MB\n",
    "\n",
    "print(f\"Model size (file): {model_size_mb:.2f} MB\")\n",
    "print(f\"Model parameters: {params_mb:.2f} MB\")\n",
    "\n",
    "# ------------------- FPS Measurement -------------------\n",
    "dummy_input = torch.randn(1, 3, 1280, 1280).to(device) / 255.0  # Normalize the dummy input\n",
    "# Warm-up\n",
    "for _ in range(5):\n",
    "    _ = model(dummy_input)  # Use the model directly for inference\n",
    "\n",
    "n_runs = 50\n",
    "start_time = time.time()\n",
    "for _ in range(n_runs):\n",
    "    _ = model(dummy_input)  # Use the model directly for inference\n",
    "end_time = time.time()\n",
    "\n",
    "fps = n_runs / (end_time - start_time)\n",
    "print(f\"Inference FPS (1280x1280): {fps:.2f}\")\n",
    "\n",
    "# ------------------- Run Validation -------------------\n",
    "print(\"\\nRunning YOLOv8 validation...\")\n",
    "start_val_time = time.time()\n",
    "model.val(\n",
    "    data=dataset_yaml,  # Validation dataset\n",
    "    imgsz=1280,          # Image size\n",
    "    batch=64,            # Corrected batch size argument\n",
    "    device=device,       # Device\n",
    "    project=results_dir, # Results directory\n",
    "    name=\"eval_metrics\", # Name for saved results\n",
    "    save_json=True,      # Save results as JSON\n",
    "    exist_ok=True,       # Overwrite if results directory exists\n",
    "    verbose=True         # Show verbose output\n",
    ")\n",
    "end_val_time = time.time()\n",
    "\n",
    "val_time = end_val_time - start_val_time\n",
    "print(f\"Validation time: {val_time:.2f} seconds\")\n",
    "print(f\"Validation results saved to {results_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35e7cbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/ultralytics/runs/detect/yolov8n_eiou_base_sgd_pat40.zip'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Specify the folder path and the destination zip file path\n",
    "folder_path = 'runs/detect/yolov8n_eiou_base_sgd_pat40'\n",
    "zip_file_path = 'runs/detect/yolov8n_eiou_base_sgd_pat40.zip'\n",
    "\n",
    "# Create a zip file from the folder\n",
    "shutil.make_archive(zip_file_path.replace('.zip', ''), 'zip', folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c6d2ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/yolov8n_eiou_base_sgd_pat40_val.zip'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Specify the folder path and the destination zip file path\n",
    "folder_path = '/workspace/yolov8n_eiou_base_sgd_pat40_val'\n",
    "zip_file_path = '/workspace/yolov8n_eiou_base_sgd_pat40_val.zip'\n",
    "\n",
    "# Create a zip file from the folder\n",
    "shutil.make_archive(zip_file_path.replace('.zip', ''), 'zip', folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b27e22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
